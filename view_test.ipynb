{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import sapien.core as sapien\n",
    "from PIL import Image\n",
    "import json\n",
    "from datagen.data_utils import *\n",
    "from pathlib import Path as P\n",
    "from utils.visualization import overlay_images\n",
    "# from utils.viewpoint import calculate_E2 as CE2\n",
    "# from utils.viewpoint import conversion_matrix_axis as cma\n",
    "from utils.viewpoint import * \n",
    "# from utils.viewpoint import conversion_matrix\n",
    "# %%\n",
    "# def setup_scene(urdf):\n",
    "#     # Set up the SAPIEN scene and camera\n",
    "#     camera, asset, scene = scene_setup(urdf_file=urdf)\n",
    "#     return camera, asset, scene\n",
    "# conversion_matrix = np.array([\n",
    "#     [0, 0, -1],\n",
    "#     [-1, 0, 0],\n",
    "#     [0, 1, 0]\n",
    "# # ])\n",
    "# def normalize(v):\n",
    "#     return v / np.sqrt(np.sum(v**2))\n",
    "\n",
    "# def calculate_E2(E1, axis_position, axis_direction, angle_degrees):\n",
    "#     # Convert the angle from degrees to radians\n",
    "#     angle_radians = degrees_to_radians(angle_degrees)\n",
    "    \n",
    "#     # Create a 3x3 rotation matrix around the axis\n",
    "#     R = get_rotation_axis_angle(axis_direction, angle_radians)\n",
    "#     # Create a 4x4 transformation matrix for the rotation\n",
    "#     rotation_matrix = np.eye(4)\n",
    "#     rotation_matrix[:3, :3] = R\n",
    "#     print(R)\n",
    "    \n",
    "#     # Create a 4x4 transformation matrix for translation to the axis position\n",
    "#     translation_matrix = np.eye(4)\n",
    "#     translation_matrix[:3, 3] = axis_position\n",
    "#     # Calculate E2 by combining translation and rotation with E1\n",
    "#     # E2 = np.dot(rotation_matrix, np.dot(rotation_matrix, E1))\n",
    "#     E2 = change_apply_change_basis(E1, rotation_matrix, translation_matrix)\n",
    "#     return E2\n",
    "\n",
    "# def change_apply_change_basis(A, T, P):\n",
    "#     \"\"\"\n",
    "#     Perform change of basis, apply transformation, and change back to the original basis.\n",
    "\n",
    "#     Args:\n",
    "#     A (numpy.ndarray): The original matrix in the B1 basis.\n",
    "#     T (numpy.ndarray): The transformation matrix to be applied.\n",
    "#     P (numpy.ndarray): The change of basis matrix from B1 to B2.\n",
    "\n",
    "#     Returns:\n",
    "#     numpy.ndarray: The resulting matrix after the entire process, expressed in the B1 basis.\n",
    "#     \"\"\"\n",
    "#     # Step 1: Change A to the B2 basis\n",
    "#     A_B2 = np.linalg.inv(P).dot(A).dot(P)\n",
    "    \n",
    "#     # Step 2: Apply the transformation T in the B2 basis\n",
    "#     A_B2_transformed = T.dot(A_B2)\n",
    "    \n",
    "#     # Step 3: Change A_B2_transformed back to the original B1 basis\n",
    "#     A_B1_transformed = P.dot(A_B2_transformed).dot(np.linalg.inv(P))\n",
    "    \n",
    "#     return A_B1_transformed\n",
    "\n",
    "# def get_rotation_axis_angle(k, theta):\n",
    "#     '''\n",
    "#     Rodrigues' rotation formula\n",
    "#     args:\n",
    "#     * k: direction vector of the axis to rotate about\n",
    "#     * theta: the (radian) angle to rotate with\n",
    "#     return:\n",
    "#     * 3x3 rotation matrix\n",
    "#     '''\n",
    "#     k = normalize(k)\n",
    "#     kx, ky, kz = k[0], k[1], k[2]\n",
    "#     cos, sin = np.cos(theta), np.sin(theta)\n",
    "#     R = np.zeros((3, 3))\n",
    "#     R[0, 0] = cos + (kx**2) * (1 - cos)\n",
    "#     R[0, 1] = kx * ky * (1 - cos) - kz * sin\n",
    "#     R[0, 2] = kx * kz * (1 - cos) + ky * sin\n",
    "#     R[1, 0] = kx * ky * (1 - cos) + kz * sin\n",
    "#     R[1, 1] = cos + (ky**2) * (1 - cos)\n",
    "#     R[1, 2] = ky * kz * (1 - cos) - kx * sin\n",
    "#     R[2, 0] = kx * kz * (1 - cos) - ky * sin\n",
    "#     R[2, 1] = ky * kz * (1 - cos) + kx * sin\n",
    "#     R[2, 2] = cos + (kz**2) * (1 - cos)\n",
    "#     return R\n",
    "\n",
    "\n",
    "# def transform_V1_to_V2(joint_state, V1, delta_rotation):\n",
    "#     try:\n",
    "#         # Extract the rotation matrix R_joint from the joint state\n",
    "#         R_joint = joint_state[:3, :3]\n",
    "\n",
    "#         u = R_joint[0, 2]\n",
    "#         v = R_joint[1, 2]\n",
    "#         w = R_joint[2, 2]\n",
    "\n",
    "\n",
    "#         # Calculate the rotation matrix R_theta for the delta rotation along the joint axis\n",
    "#         cos_theta = np.cos(delta_rotation)\n",
    "#         sin_theta = np.sin(delta_rotation)\n",
    "#         R_theta = np.array([[cos_theta + u**2 * (1 - cos_theta), u * v * (1 - cos_theta) - w * sin_theta, u * w * (1 - cos_theta) + v * sin_theta],\n",
    "#                             [v * u * (1 - cos_theta) + w * sin_theta, cos_theta + v**2 * (1 - cos_theta), v * w * (1 - cos_theta) - u * sin_theta],\n",
    "#                             [w * u * (1 - cos_theta) - v * sin_theta, w * v * (1 - cos_theta) + u * sin_theta, cos_theta + w**2 * (1 - cos_theta)]])\n",
    "\n",
    "\n",
    "#         # Create 4x4 transformation matrices\n",
    "#         T_joint = np.eye(4)\n",
    "#         T_joint[:3, :3] = R_joint\n",
    "\n",
    "#         T_theta = np.eye(4)\n",
    "#         T_theta[:3, :3] = R_theta\n",
    "\n",
    "#         # Compute V2 by multiplying the transformation matrices\n",
    "#         # V2 = np.dot(np.dot(np.dot(T_joint, T_theta), np.linalg.inv(T_joint)), V1)\n",
    "#         V2_prime = np.dot(np.linalg.inv(T_joint), np.dot(T_theta, V1))\n",
    "#         V2 = np.dot(V2_prime, T_joint)\n",
    "\n",
    "#         return V2\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error calculating V2: {str(e)}\")\n",
    "#         return None\n",
    "# def degrees_to_radians(degrees):\n",
    "#     radians = degrees * (math.pi / 180)\n",
    "#     return radians\n",
    "def render_image(camera, scene, save_path):\n",
    "    # Render an image using the provided camera and save it to the specified path\n",
    "    scene.step()\n",
    "    scene.update_render()\n",
    "    camera.take_picture()\n",
    "    rgba = camera.get_float_texture('Color')\n",
    "    rgba_img = (rgba * 255).clip(0, 255).astype(\"uint8\")\n",
    "    rgba_pil = Image.fromarray(rgba_img, 'RGBA')\n",
    "    rgba_pil.save(save_path)\n",
    "\n",
    "def load_json_to_dict(fname):\n",
    "    # Load JSON data from a file into a dictionary\n",
    "    try:\n",
    "        with open(fname, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading JSON from {fname}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{'axis': {'origin': [0, -0.007706040424053753, -0.24714714808389615], 'direction': [1, 0, 0]}, 'limit': {'a': 105.11999999999999, 'b': -27, 'noLimit': False}}\n",
      "point\n",
      "(-2.8942773678193205, 3.9836310418954106, -0.8682408883346515)\n",
      "mat44:\n",
      "[[ 0.57885547  0.80901699 -0.10206784 -2.89427737]\n",
      " [-0.79672621  0.58778525  0.14048433  3.98363104]\n",
      " [ 0.17364818 -0.          0.98480775 -0.86824089]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[ 0.98480775 -0.         -0.17364818]\n",
      " [ 0.          1.         -0.        ]\n",
      " [ 0.17364818  0.          0.98480775]]\n",
      "Pose([0, 0, 0], [0.996195, 0, -0.0871557, 0])\n"
     ]
    }
   ],
   "source": [
    "urdf = 'data_base/laptop/10211/mobility.urdf'\n",
    "# Load JSON data\n",
    "json_fname = './data_base/laptop/10211/mobility_v2.json'\n",
    "meta = load_json_to_dict(json_fname)\n",
    "for link in meta:\n",
    "    if link['joint'] == 'hinge':\n",
    "        print(link['id'])\n",
    "        print(link['jointData'])\n",
    "        origin =  link['jointData']['axis']['origin']\n",
    "        direction =  link['jointData']['axis']['direction']\n",
    "# Setup the scene\n",
    "camera, asset, scene = scene_setup(urdf)\n",
    "# %%\n",
    "# point = random_point_in_sphere(5, theta_range=[-0.01 * math.pi, 0.01*math.pi], phi_range=[0.01*math.pi, 0.01*math.pi])\n",
    "\n",
    "def point_in_sphere(r, theta, phi):\n",
    "    x = r * math.sin(phi) * math.cos(theta)\n",
    "    y = r * math.sin(phi) * math.sin(theta)\n",
    "    z = r * math.cos(phi)\n",
    "    \n",
    "    return x, y, z\n",
    "\n",
    "point = point_in_sphere(5, 0.7*math.pi, degrees_to_radians(100))\n",
    "mat44 = calculate_cam_ext(point)\n",
    "print(\"point\")\n",
    "print(point)\n",
    "print('mat44:')\n",
    "print(mat44)\n",
    "# print(point)\n",
    "# mat44 = np.eye(4)\n",
    "# mat44[0, -1] = 4\n",
    "# mat44[1, -1] = 2\n",
    "# mat44[2, -1] = 1\n",
    "camera.set_pose(sapien.Pose.from_transformation_matrix(mat44))\n",
    "# Render image with default pose\n",
    "render_image(camera, scene, './draft/test_view.png')\n",
    "seg_labels = camera.get_uint32_texture('Segmentation')  # [H, W, 4]\n",
    "seg_view = seg_labels[..., 1].astype(np.uint8)  # actor-level\n",
    "seg_pil = Image.fromarray(seg_view)\n",
    "seg_pil.save('./draft/test_view_seg.png')\n",
    "view_0 = camera.get_model_matrix()\n",
    "art_degree = 10\n",
    "\n",
    "# Rotate the joint and render a new image\n",
    "asset.set_qpos(degrees_to_radians(art_degree))\n",
    "render_image(camera, scene, './draft/test_view_15.png')\n",
    "seg_labels = camera.get_uint32_texture('Segmentation')  # [H, W, 4]\n",
    "seg_view_15 = seg_labels[..., 1].astype(np.uint8)  # actor-level\n",
    "seg_view_15 = Image.fromarray(seg_view_15)\n",
    "seg_view_15.save('./draft/test_view_15_seg.png')\n",
    "# Calculate joint state and transformation\n",
    "joint_state = asset.get_links()[-1].pose.to_transformation_matrix()\n",
    "# v2 = transform_V1_to_V2(joint_state, mat44, degrees_to_radians(15))\n",
    "\n",
    "\n",
    "# dirs, ori = np.dot(conversion_matrix, direction), np.dot(conversion_matrix, origin)\n",
    "\n",
    "\n",
    "# v2 = calculate_E2(mat44, ori, dirs, art_degree)\n",
    "v2 = calculate_E2(mat44, origin, direction, art_degree)\n",
    "# view_2 = calculate_E2(view_0, np.array(origin), np.array(direction), art_degree)\n",
    "# Set the new joint configuration and render the image\n",
    "asset.set_qpos(0)\n",
    "camera.set_pose(sapien.Pose.from_transformation_matrix(v2))\n",
    "render_image(camera, scene, './draft/test_view_15_v2.png')\n",
    "seg_labels = camera.get_uint32_texture('Segmentation')  # [H, W, 4]\n",
    "seg_view_15_v2 = seg_labels[..., 1].astype(np.uint8)  # actor-level\n",
    "seg_view_15_v2_pil = Image.fromarray(seg_view_15_v2)\n",
    "seg_view_15_v2_pil.save('./draft/test_view_15_v2_seg.png')\n",
    "\n",
    "view_1 = camera.get_model_matrix()\n",
    "\n",
    "\n",
    "inerf_json = {\n",
    "    'view_0': view_0.tolist(),\n",
    "    'view_1': view_1.tolist()\n",
    "}\n",
    "\n",
    "with open('./draft/inerf_pose.json', 'w') as f:\n",
    "    json.dump(inerf_json, f)\n",
    "\n",
    "\n",
    "# Overlay images\n",
    "rgba_15_pil = Image.open('./draft/test_view_15.png')\n",
    "rgba_v2_pil = Image.open('./draft/test_view_15_v2.png')\n",
    "overlayed = overlay_images(rgba_15_pil, rgba_v2_pil, 0.5)\n",
    "overlayed.save('./draft/overlayed_view.png')\n",
    "\n",
    "\n",
    "rgba_pil = Image.open('./draft/test_view.png')\n",
    "overlayed = overlay_images(rgba_pil, rgba_15_pil, 0.5)\n",
    "overlayed.save('./draft/overlayed_art.png')\n",
    "\n",
    "overlayed = overlay_images(rgba_pil, rgba_v2_pil, 0.5)\n",
    "overlayed.save('./draft/overlayed_base.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose rotation\n",
      "[[-5.78855515e-01 -8.09017062e-01 -1.02067828e-01]\n",
      " [ 7.96726227e-01 -5.87785244e-01  1.40484333e-01]\n",
      " [-1.73648238e-01  2.98023224e-08  9.84807730e-01]]\n",
      "view\n",
      "[[-8.0901706e-01 -1.0206783e-01 -5.7885551e-01 -2.8942773e+00]\n",
      " [-5.8778524e-01  1.4048433e-01  7.9672623e-01  3.9836311e+00]\n",
      " [ 2.9802322e-08  9.8480773e-01 -1.7364824e-01 -8.6824089e-01]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00]]\n",
      "view2pose\n",
      "[[-8.0901706e-01 -1.0206783e-01 -5.7885551e-01 -2.8942773e+00]\n",
      " [-5.8778524e-01  1.4048433e-01  7.9672623e-01  3.9836311e+00]\n",
      " [ 2.9802322e-08  9.8480773e-01 -1.7364824e-01 -8.6824089e-01]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00]]\n",
      "mannual\n",
      "[[ 5.78855515e-01 -8.09017062e-01  1.02067828e-01 -2.89427733e+00]\n",
      " [ 7.96726227e-01  5.87785244e-01 -1.40484333e-01  3.98363113e+00]\n",
      " [-1.73648238e-01  2.98023224e-08  9.84807730e-01 -8.68240893e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "view_0 # view\n",
    "print(view2pose(view_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57885547  0.80901699 -0.10206784 -2.89427737]\n",
      " [-0.79672621  0.58778525  0.14048433  3.98363104]\n",
      " [ 0.17364818 -0.          0.98480775 -0.86824089]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[ 0.10206784 -0.57885547  0.80901699 -2.89427737]\n",
      " [-0.14048433  0.79672621  0.58778525  3.98363104]\n",
      " [-0.98480775 -0.17364818  0.         -0.86824089]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "mat44 # pose\n",
    "print(mat44)\n",
    "print(view2pose(mat44))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform test with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "diff = view_0 - pose2view(mat44)\n",
    "diff[abs(diff) < 1e-7] = 0\n",
    "print(diff)\n",
    "\n",
    "diff = mat44 - view2pose(pose2view(mat44))\n",
    "diff[abs(diff) < 1e-7] = 0\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform test with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.887616  , -0.03956788, -0.07765634, -0.45226294], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "mat44_torch = torch.Tensor(mat44)\n",
    "view_torch = torch.Tensor(view_0)\n",
    "pose = sapien.Pose.from_transformation_matrix(mat44)\n",
    "pose.q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "diff = view_torch - pose2view_torch(mat44_torch)\n",
    "diff[abs(diff) < 1e-7] = 0\n",
    "print(diff)\n",
    "\n",
    "diff = mat44_torch - view2pose_torch(pose2view_torch(mat44_torch))\n",
    "diff[abs(diff) < 1e-7] = 0\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori, dirs = convert_ori_dir(origin, direction)\n",
    "\n",
    "# Convert the angle from degrees to radians\n",
    "angle_radians = degrees_to_radians(art_degree)\n",
    "\n",
    "# Create a 3x3 rotation matrix around the axis\n",
    "R = get_rotation_axis_angle(dirs, angle_radians)\n",
    "\n",
    "from utils.rotation import *\n",
    "Q = matrix_to_quaternion(torch.Tensor(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9962,  0.0000, -0.0872,  0.0000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9961947 ,  0.        , -0.08715574,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mat44 = np.eye(4)\n",
    "test_mat44[:3, :3] = R\n",
    "test_pose = sapien.Pose.from_transformation_matrix(test_mat44)\n",
    "test_pose.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24714715,  0.        , -0.00770604])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
