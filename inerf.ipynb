{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iNERF test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.vanilla_nerf.model import NeRF\n",
    "from PIL import Image\n",
    "from pathlib import  Path as P\n",
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from datasets.ray_utils import get_ray_directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(json_fname):\n",
    "    with open(json_fname, 'r') as json_file:\n",
    "        data_dict = json.load(json_file)\n",
    "    return data_dict\n",
    "\n",
    "def remove_model_prefix(input_dict):\n",
    "    \"\"\"\n",
    "    Remove the \"model.\" prefix from all key names in a dictionary.\n",
    "\n",
    "    Args:\n",
    "        input_dict (dict): The input dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary with the \"model.\" prefix removed from key names.\n",
    "    \"\"\"\n",
    "    output_dict = {}\n",
    "    for key, value in input_dict.items():\n",
    "        # Check if the key starts with \"model.\"\n",
    "        if key.startswith(\"model.\"):\n",
    "            # Remove the \"model.\" prefix and add to the new dictionary\n",
    "            new_key = key[len(\"model.\"):]\n",
    "            output_dict[new_key] = value\n",
    "        else:\n",
    "            # If the key doesn't start with \"model.\", add it as is\n",
    "            output_dict[key] = value\n",
    "    return output_dict\n",
    "\n",
    "def load_model_with_check(model, state_dict_dict):\n",
    "    \"\"\"\n",
    "    Load a PyTorch model's state_dict from a dictionary and report missing\n",
    "    and unexpected keys.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to which the state_dict should be loaded.\n",
    "        state_dict_dict (dict): The state_dict dictionary.\n",
    "\n",
    "    Returns:\n",
    "        model (torch.nn.Module): The model with the loaded state_dict.\n",
    "        missing_keys (list): List of keys that were in the state_dict but not in the model.\n",
    "        unexpected_keys (list): List of keys that were in the model but not in the state_dict.\n",
    "    \"\"\"\n",
    "    # Load the state_dict\n",
    "    state_dict = state_dict_dict\n",
    "\n",
    "    # Load the model's state_dict and track missing and unexpected keys\n",
    "    missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    # Report missing and unexpected keys\n",
    "    if missing_keys:\n",
    "        print(\"Missing keys in the model's state_dict:\")\n",
    "        for key in missing_keys:\n",
    "            print(key)\n",
    "    if unexpected_keys:\n",
    "        print(\"Unexpected keys found in the model's state_dict:\")\n",
    "        for key in unexpected_keys:\n",
    "            print(key)\n",
    "\n",
    "    return model, missing_keys, unexpected_keys\n",
    "\n",
    "def select_element(value, seg, part_num=0):\n",
    "    # Squeeze the seg tensor to remove the singleton dimension\n",
    "    seg = seg.squeeze(dim=1)\n",
    "    \n",
    "    # Create a mask for the selected segments\n",
    "    mask = (seg == part_num)\n",
    "\n",
    "    # Apply the mask to the value tensor to select the desired elements\n",
    "    selected_value = value[mask]\n",
    "\n",
    "    return selected_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = P(\"./data/laptop_art_same_pose/train/idx_1/\")\n",
    "device = 'cuda'\n",
    "transform_meta = load_json(str(root_path / 'transforms.json'))\n",
    "frame_id = 'r_0'\n",
    "pose_np = np.array(transform_meta['frame'][frame_id])\n",
    "rgb_pil = Image.open(str(root_path/'rgb'/(frame_id + '.png')))\n",
    "seg_pil = Image.open(str(root_path/'seg'/(frame_id + '.png')))\n",
    "pose = torch.Tensor(pose_np).to(device)\n",
    "rgb = transforms.ToTensor()(rgb_pil).to(device)\n",
    "rgb = rgb.view(4, -1).permute(1, 0) # (H*W, 4) RGBA\n",
    "rgb = rgb[:, :3]*rgb[:, -1:] + (1-rgb[:, -1:]) # blend A to RGB\n",
    "seg_np = np.array(seg_pil)\n",
    "seg = torch.Tensor(seg_np).to(device).view([1, -1]).permute(1, 0)\n",
    "seg = seg.type(torch.LongTensor)\n",
    "seg = seg - 1 # starts with 2\n",
    "seg[seg<0] = 0\n",
    "focal = transform_meta['focal']\n",
    "h, w = 640, 480\n",
    "directions = get_ray_directions(h, w, focal).view([-1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeRF model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ckpt state_dict\n",
    "ckpt_file = \"results/laptop/nerf_laptop/last.ckpt\"\n",
    "ckpt_dict_model = torch.load(ckpt_file)['state_dict']\n",
    "ckpt_dict = remove_model_prefix(ckpt_dict_model)\n",
    "# initialize model and load pre-trained weights\n",
    "model = NeRF()\n",
    "model, _, _ = load_model_with_check(model, ckpt_dict)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add view transform variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViewTransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        initialize_param = torch.Tensor([\n",
    "            [1, 0, 0, 0], \n",
    "            [0, 1, 0, 0],\n",
    "            [0, 0, 1, 0]\n",
    "        ]).view([-1])\n",
    "        \n",
    "        self.weight = nn.Parameter(initialize_param, requires_grad = True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input: 4x4 c2w matrix\n",
    "        \"\"\"\n",
    "        constant = torch.Tensor([\n",
    "            [0, 0, 0, 1]\n",
    "        ]).to(dtype=self.weight.dtype, device=self.weight.device)\n",
    "        \n",
    "        weight = torch.cat((self.weight.view([3, 4]), constant), dim=0)\n",
    "        new_view_point = torch.matmul(weight, input)\n",
    "        return new_view_point\n",
    "\n",
    "view_deform = ViewTransform().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configure optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(view_deform.parameters(), lr=1e-2, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vanilla_nerf.model_nerfseg import  get_rays_torch\n",
    "from models.vanilla_nerf.helper import img2mse\n",
    "\n",
    "directions = directions.to(device)\n",
    "# gather directions and rgbs based on part label from seg (select value where seg == part_num)\n",
    "# help me write the function select_element(value, seg, part_num=0), value in shape [N, k], seg in shape [N, 1], return [n, k]\n",
    "selected_dirs = select_element(directions, seg, part_num=2).to(device)\n",
    "selected_rgbs = select_element(rgb, seg, part_num=2).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14282, 3])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_dirs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m/home/dj/git/articulated-object-nerf/inerf.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/dj/git/articulated-object-nerf/inerf.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# update variable\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/dj/git/articulated-object-nerf/inerf.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/dj/git/articulated-object-nerf/inerf.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/ao/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ao/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [14282, 3]], which is output 0 of DivBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimize_step = 30\n",
    "result = []\n",
    "# loop over the following steps until converge or optimize for a certain number of step\n",
    "for _ in range(optimize_step):\n",
    "    optimizer.zero_grad()\n",
    "    # go through view_deform module to get new view point matrix\n",
    "    new_pose = view_deform(pose)\n",
    "    # generate rays with new_view_point and selected directions\n",
    "    rays_o, viewdirs, rays_d = get_rays_torch(selected_dirs, new_pose[:3, :], output_view_dirs=True)\n",
    "    # gather input_dict for NeRF\n",
    "    input_dict = {\n",
    "        'rays_o': rays_o,\n",
    "        'rays_d': rays_d,\n",
    "        'viewdirs': viewdirs\n",
    "    }\n",
    "    # gather rendered resutls from NeRF coarse and fine\n",
    "    rendered_results = model(input_dict, False, True, 2, 6, )\n",
    "    coarse_rgb = rendered_results[0][0]\n",
    "    fine_rgb = rendered_results[1][0]\n",
    "    # calculate and print loss\n",
    "    loss0 = img2mse(coarse_rgb, selected_rgbs)\n",
    "    loss1 = img2mse(fine_rgb, selected_rgbs)\n",
    "    loss = loss0 + loss1\n",
    "    # update variable\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.3541e-01,  2.9152e-01, -2.0005e-01, -1.0130e+00],\n",
       "        [-3.5356e-01, -7.7128e-01,  5.2926e-01,  2.6800e+00],\n",
       "        [-7.4506e-09,  5.6581e-01,  8.2454e-01,  4.1751e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
